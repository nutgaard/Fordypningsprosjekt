\chapter{Related work}\label{ch:related}
Explaining and predicting academic performance has been researched a lot in other fields than computer science. Many studies look at the psychological aspect of students that choose to quit studying or are preforming under the standards. Not many of these existing techniques take all the data available on students into account. Data mining in this context can therefore be very helpful. Not only by organizing the data into an easier analyzable way for counselors, but also by trying to classify and analyze both students and education in general. Recently a lot of research has gone into this and the term Educational Data Mining~\cite{1} was born.

\bigskip\noindent
Educational Data Mining includes everything about data mining in an educational context.
We are especially interested in what classification algorithms have to offer. 
Classification in EDM can be used in many ways, such as:
providing feedback for supporting instructors,
make recommendations for students,
predict student performance,
detect undesirable student behaviors,
constructing course content and custom tutoring,
analyze social networks and much more.
It is still not clear which methods are most effective in this context, but most papers so far agree that decision trees~\cite{2,12} or rule implying algorithms are the best approach.
It is not yet proven, albeit we need an understandable way to represent the data found, and rule based or decision tree algorithms give us exactly this. 

\bigskip\noindent
A lot of papers have the same main problem as us, predicting dropout prone students~\cite{5,7,8,9,11} .
This is an important area of research as many universities use a lot of time, 
money and effort in educating students who will not complete their degree. 
These education spots could even be occupied by more focused students. 
Some of these students drop out because of external events, but some might be able to finish with the right help. 
It is therefore important to find these students to either help them or drop them from the study. 

\bigskip\noindent
Some other, often more statistical papers talk about the importance of social data. 
This can be in the form of data from student conversations with counselors~\cite{11}.

\section{Classification}\label{ch:relclass}
One of the papers has very similar goals and use the same techniques as us~\cite{7}.
They look at students in an electrical engineering program. 
They classified a successful student as having done all his 1 year courses in 3 years. 
This is more or less accurate but there are outliers. 
They run some tests on 3 datasets, one with university data only, one with pre-university data only and one combination of both. 
%Only one is relevant to us, the dataset containing university grades only, since we will not have access to earlier data yet. 
They then ran different decision tree algorithms on the data with 10 fold cross validation. 
The only university data used here was grades and number of tries in 74 different courses. 
With only the highest grades for the 37 available courses and how many attempts were taken pr course.
The algorithms had an accuracy between 75 and 80\% on dropout, which is very promising.

\bigskip\noindent
A data mining tool has been developed for Moodle (Moodle is a Learning Management System similar to its-learning)~\cite{12}.
They use this mining tool to compare different data mining techniques when classifying students based on their Moodle usage. 
This might be interesting but not many lecturers or students use its-learning to its full extent. 

\bigskip\noindent
An interesting paper writes about identifying cellular phone failures~\cite{3}.
Their task is not to predict any failure but to identify possible causes that resulted in failures.  
This is similar to our case since we try to find causes of dropout and not just classify the students.
Decision trees provide good accuracy and explanatory results but this paper had problems with decision trees only finding enough rules to most correctly classify their data.
They have used a technique called Class Association Rules which only mines rules with a class as the implied attribute. 
This is a subset of association rules and can greatly increase performance if there are too many attributes.
This technique will enable us to mine all the rules with high enough confidence and support and maybe draw some interesting conclusions about attributes which may otherwise be left out.
Class Association Rule mining is further explained in~\cite{4}.

\section{Data preprocessing}
Anonymizing a collection of data is very important when dealing with sensitive data. 
Especially if the results are going to be publicly available. 
A lot of times even if you remove name, id and so on there might be a certain combination of attributes that yield an induviduals identity.
An approach called \textit{k-anonymization} which maintains the classification structure is proposed, 
which basically makes it so that at least $k$ instances contains every combination of linked attributes. 
A top-down approach to refine the data, maximizing the trade-off between information and anonymity is presented.~\cite{14}

\bigskip\noindent
We need to discretize our data for some of the classification algorithms.
We can put grades into buckets, for example \textless C, C and \textgreater C into buckets called FAIL, PASS and GOOD~\cite{12}.

\bigskip\noindent
Reducing the number of attributes, in our case the number of courses is also important to avoid anomalies and reduce space usage in the database.
It has been shown that not only can classification properties of the data be preserved, but the accuracy can increase for certain algorithms as well~\cite{9}.
This is also important because students can take different courses, so some of these attributes may not be very relevant. 
In the worst case it might even cause false results and conclusions in the classification process.

\bigskip\noindent
One of the biggest issues in many papers is that the dataset is not balanced. 
Data is imbalanced when one class is represented by a significantly larger amount of instances than another~\cite{10}. 
An imbalanced boolean dataset might look like this: class 1 is represented by 10 instances and class 0 is represented by 200 instances. 
Learning a classifier from such datasets poses a problem. 
A class that is poorly represented will yield bad misclassification accuracy, 
even though the accuracy for the dataset as a whole might be high. 
This is an important issue in our discussion as our dataset is imbalanced and the poorly represented class is the most important one, 
we want to find students which will most likely drop out.

\bigskip\noindent
As mentioned the accuracy might be high overall but not for the spesiffic classes we want.
A better measure for classifiers built on imbalanced datasets is the geometric mean. 
This is usually used in these circumstances~\cite{12}. 

\bigskip\noindent
Balancing out the dataset can be done in multiple ways. 
Random over-sampling copies random instances of an underrepresented class until the classes are represented by an equal amount of instances~\cite{12}. 
Synthetic Minority Over-sampling Technique(SMOTE) introduces new minority instances synthetically from the nearest neighbour of equal class~\cite{9}. 
Cost-sensitive classification lets you put weights on the classes so the classifier is built to maximize the accuracy based on these weights~\cite{9}. 
We can specify that fail students are 5 times as important to classify correctly then pass students. 
When changing the dataset for classification it is important to test on the original dataset if you are testing on and building the classifier from the same dataset.

\bigskip\noindent
The task of mining on imbalanced datasets is further explained in~\cite{10}.
They also discuss existing data mining tools for imbalanced datasets in~\cite{8}.

\bigskip\noindent
All these papers have different datasets and focuses on results but none of them take all the concerns stated in the others into account. 
Some might discretize attribute values but not take into account the imbalanced datasets and visa versa.

\section{Educational Decision Support System}
An educational decision support system (EDSS) has been proposed~\cite{5} to optimize effort, time and money for both educators and students. 
The university this study took place in kicks out students who under perform 1 or 2 semesters in a row.
The focus is therefore on finding the students that will not be able to finish their studies and who should be given a second chance. 
The university manage a warning list of who will be forced to stop their study. 
This list represents students that don't have the necessary knowledge to make it in the next semester. 
Students may get one extra semester to escape the warning list. 
If the wrong students are given a new chance, time, money and effort will be lost. 
The EDSS therefore focuses on making the most reasonable decisions they can in maintaining this warning list. 
With over 1348 undergrad students they got a 97\% student classification accuracy.

\bigskip\noindent
A second paper also discusses the problem of making correct academic decisions~\cite{6}. 
Different ways of analyzing performance data is discussed and a software package called PADSS(Performance-based Academic Decision-Support System) is developed. 
Through this software package he importance of the data extracted from the grades and registration databases has been shown. 
The system in conclusion is described as extremely useful and a critically important tool for general university performance analysis.
It offers great insight for major academic decisions.